---
title: AUC
date: 2020-06-16 19:01:32
tags: AUC
categories:
top:
---

AUC: Area Under Curve, 默认为ROC(**receiver operating characteristic curve**) Curve, 也可以指定PR(Precision Recall) curve。

![](https://bkimg.cdn.bcebos.com/pic/f11f3a292df5e0feaafde78c566034a85fdf7251?x-bce-process=image/watermark,g_7,image_d2F0ZXIvYmFpa2U4MA==,xp_5,yp_5)

由于ROC曲线的X轴为False Positive Rate，Y轴为True Positive Rate，AUC是可以指 **随机给定一个正样本和一个负样本，分类器输出该正样本为正的 比 输出该负样本为正 要大的概率**，即 AUC = P(P_tpr > P_fpr).

<!-- more -->

AUC的计算方法：

在有M个正样本,N个负样本的数据集里。一共可构成 M*N 个样本对（一对样本即，一个正样本与一个负样本）。统计这M*N对样本里，正样本的预测概率大于负样本的预测概率的个数。
$$
A U C=\frac{\sum_{i \in \text { positiveclass }} \operatorname{rank}_{i}-\frac{M(1+M)}{2}}{M \times N}
$$

```python
def AUC(label, pre):
　　#计算正样本和负样本的索引，以便索引出之后的概率值
    pos = [i for i in range(len(label)) if label[i] == 1]
    neg = [i for i in range(len(label)) if label[i] == 0]

    auc = 0
    for i in pos:
        for j in neg:
            if pre[i] > pre[j]:
                auc += 1
            elif pre[i] == pre[j]:
                auc += 0.5

    return auc / (len(pos)*len(neg))


if __name__ == '__main__':
    label = [1,0,0,0,1,0,1,0]
    pre = [0.9, 0.8, 0.3, 0.1, 0.4, 0.9, 0.66, 0.7]
    print(AUC(label, pre))

    from sklearn.metrics import roc_curve, auc
    fpr, tpr, th = roc_curve(label, pre , pos_label=1)
    print('sklearn', auc(fpr, tpr))
```



1、多分类可以计算AUC吗？

​	可以。通过one VS rest可以得到M个AUC，最后求均值。

2、AUC的阈值怎么选取最佳？

​	曲线靠近左上角对应的阈值最佳，代表TPR大于FPR的最大机会。

3、类别不平衡对AUC_roc和AUC_pr哪个影响大？

​	**ROC不受训练集类别分布的影响**

References:

1、 [AUC的计算方法](https://blog.csdn.net/qq_22238533/article/details/78666436)
